# model
pre_train_model_path: "../../pre_trained_model/NLP/bigbird-roberta-base"
out_size: 6
dropout_rate: [0.2, 0.3, 0.4]

# data
batch_size: 2
seq_len: 3000
num_workers: 0
train_data_path: "./data/ori_train.csv"
test_data_path: "./data/test.csv"
target_cols: ["cohesion", "syntax", "vocabulary", "phraseology", "grammar", "conventions"]
n_fold: 5

# training
weight_decay: 1.0e-6
lr: 5.0e-5
epochs: 10
metric_key: "MCRMSE"
patience: 3
max_norm: 10
adv_lr: 1.0e-3    # 对抗训练lr
adv_eps: 1.0e-3   # 对抗训练eps

# save
model_save_path: "./saved_model/version_0913/"